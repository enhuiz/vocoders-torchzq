runner: python -m vocoders_torchzq.runners.universal

dist: Î¼law

batch_size: 16
eval_batch_size: 8

train:
  max_epochs: 1000
  save_every_epoch: 4
  validate_every_epoch: 2
  grad_clip_thres: 1.0
  lr: "lambda i: max(4.0e-4 * 0.5 ** (i / 20000), 1e-5)"
