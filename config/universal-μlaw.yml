runner: python -m vocoders_torchzq.runners.universal

dist: Î¼law

batch_size: 16
eval_batch_size: 8

train:
  max_epochs: 1000
  save_every_epoch: 10
  validate_every_epoch: 5
  grad_clip_thres: 1.0
  lr: "lambda i: 2e-4 * min(i / 2000, 1)"
